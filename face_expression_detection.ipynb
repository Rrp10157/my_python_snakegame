{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3kiP+ZdtiWjwoC34Em4rP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rrp10157/my_python_snakegame/blob/main/face_expression_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g87jm67uFwvh"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.utils\n",
        "from pandas import read_csv\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    The datasets built from the CSV data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, images, labels):\n",
        "        \"\"\"\n",
        "        Create the dataset.\n",
        "        :param images: The images parsed from the CSV.\n",
        "        :param labels: The labels parsed from the CSV.\n",
        "        \"\"\"\n",
        "        self.images = torch.tensor(images, dtype=torch.float32)\n",
        "        # Rearrange axis to get them in proper input order and appear visually upright.\n",
        "        self.images = torch.swapaxes(self.images, 1, 3)\n",
        "        self.images = torch.swapaxes(self.images, 2, 3)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.int)\n",
        "        self.transform = None\n",
        "\n",
        "    def set_transform(self, percent: float):\n",
        "        \"\"\"\n",
        "        Define the transform for the dataset.\n",
        "        :param percent: A value between 0 and 1 for what extent to apply the transformations.\n",
        "        :return: Nothing.\n",
        "        \"\"\"\n",
        "        # If no 0, don't apply transformations.\n",
        "        if percent <= 0:\n",
        "            self.transform = None\n",
        "            return\n",
        "        self.transform = transforms.Compose([\n",
        "            # Randomly flip the image.\n",
        "            transforms.RandomHorizontalFlip(0.5 * percent),\n",
        "            # Randomly adjust pixel values.\n",
        "            transforms.ColorJitter(brightness=0.5 * percent, contrast=0.3 * percent, hue=0.3 * percent, saturation=0.3 * percent),\n",
        "            # Randomly rotate the training data to add more variety.\n",
        "            transforms.RandomRotation(20 * percent),\n",
        "            # Randomly adjust image perspective.\n",
        "            transforms.RandomPerspective(0.25 * percent),\n",
        "            # Randomly zoom in on training data to add more variety.\n",
        "            transforms.RandomResizedCrop(48, (1 - 0.3 * percent, 1), antialias=True)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the length of the dataset.\n",
        "        :return: The length of the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get an image and its label from the dataset.\n",
        "        :param idx: The index to get.\n",
        "        :return: The image with transformations applied and its label.\n",
        "        \"\"\"\n",
        "        return (self.images[idx] if self.transform is None else self.transform(self.images[idx])), self.labels[idx].type(torch.LongTensor)\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    The neural network to train for the face dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str):\n",
        "        \"\"\"\n",
        "        Set up the neural network loading in parameters defined in 'model_builder.py'.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Load in defined parameters.\n",
        "        self.layers = NeuralNetwork.define_layers(name)\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.parameters())\n",
        "        # Run on GPU if available.\n",
        "        self.to(get_processing_device())\n",
        "\n",
        "    @staticmethod\n",
        "    def define_layers(name: str):\n",
        "        \"\"\"\n",
        "        Build the layers of the neural network.\n",
        "        Convolutional Size =  (Size - Kernel + 2 * Padding) / Stride + 1\n",
        "        Pooling Size =        (Size + 2 * Padding - Kernel) / Stride + 1\n",
        "        Flatten Size =        Last Convolutional Out Channels * Size^2\n",
        "        :param name: The name of the model architecture to use.\n",
        "        :return: A sequential layer structure which has a 48x48 single channel starting input layer and a 7 final output layer.\n",
        "        \"\"\"\n",
        "        return NeuralNetwork.resnet_network() if name == \"ResNet\" else NeuralNetwork.simple_network()\n",
        "\n",
        "    @staticmethod\n",
        "    def simple_network():\n",
        "        \"\"\"\n",
        "        A network composing of several, decreasing in size convolutional layers.\n",
        "        :return: A simple CNN.\n",
        "        \"\"\"\n",
        "        return nn.Sequential(\n",
        "            # First convolutional layer.\n",
        "            nn.Conv2d(1, 64, 3, padding=1),  # (48 - 3 + 2 * 1) / 1 + 1 = 48\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # (48 + 2 * 0 - 2) / 2 + 1 = 24\n",
        "            # Second convolutional layer.\n",
        "            nn.Conv2d(64, 64, 3, padding=1),  # (24 - 3 + 2 * 1) / 1 + 1 = 24\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # (24 + 2 * 0 - 2) / 2 + 1 = 12\n",
        "            # Third convolutional layer.\n",
        "            nn.Conv2d(64, 64, 3, padding=1),  # (12 - 3 + 2 * 1) / 1 + 1 = 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # (12 + 2 * 0 - 2) / 2 + 1 = 6\n",
        "            # Fourth convolutional layer.\n",
        "            nn.Conv2d(64, 64, 3, padding=1),  # (6 - 3 + 2 * 1) / 1 + 1 = 6\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # (6 + 2 * 0 - 2) / 2 + 1 = 3\n",
        "            # Append the final learning layers.\n",
        "            NeuralNetwork.final_layers()\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def resnet_network():\n",
        "        \"\"\"\n",
        "        Model based on the ResNet18 architecture.\n",
        "        :return: A ResNet18 based model.\n",
        "        \"\"\"\n",
        "        # ResNet18 network with pretrained weights.\n",
        "        resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        return nn.Sequential(\n",
        "            # Prepare data to be fed into the ResNet18 model.\n",
        "            nn.AdaptiveAvgPool2d(224),\n",
        "            nn.Conv2d(1, 3, 3),\n",
        "            # Pass to ResNet18.\n",
        "            resnet,\n",
        "            # Append the final learning layers.\n",
        "            NeuralNetwork.final_layers()\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def final_layers():\n",
        "        \"\"\"\n",
        "        The final linear learning layers of the models.\n",
        "        :return: Several linear learning and the final output layers.\n",
        "        \"\"\"\n",
        "        return nn.Sequential(\n",
        "            # Flatten the output of the ResNet model and apply further processing.\n",
        "            nn.Flatten(),\n",
        "            # Automatically handle scaling the flattened layer into 64 neurons.\n",
        "            nn.Dropout(),\n",
        "            nn.LazyLinear(64),\n",
        "            nn.ReLU(),\n",
        "            # Second final learning layer.\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            # Third final learning layer.\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            # Final predictions layer.\n",
        "            nn.Linear(64, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "        \"\"\"\n",
        "        Feed forward an image into the neural network.\n",
        "        :param image: The image as a proper tensor.\n",
        "        :return: The final output layer from the network.\n",
        "        \"\"\"\n",
        "        return self.layers(image)\n",
        "\n",
        "    def predict(self, image):\n",
        "        \"\"\"\n",
        "        Get the network's prediction for an image.\n",
        "        :param image: The image as a proper tensor.\n",
        "        :return: The number the network predicts for this image.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Get the highest confidence output value.\n",
        "            return torch.argmax(self.forward(image), axis=-1)\n",
        "\n",
        "    def optimize(self, image, label):\n",
        "        \"\"\"\n",
        "        Optimize the neural network to fit the training data.\n",
        "        :param image: The image as a proper tensor.\n",
        "        :param label: The label of the image.\n",
        "        :return: The network's loss on this prediction.\n",
        "        \"\"\"\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = self.loss(self.forward(image), label)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "def get_processing_device():\n",
        "    \"\"\"\n",
        "    Get the device to use for training, so we can use the GPU if CUDA is available.\n",
        "    :return: The device to use for training being a CUDA GPU if available, otherwise the CPU.\n",
        "    \"\"\"\n",
        "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def to_tensor(tensor, device=get_processing_device()):\n",
        "    \"\"\"\n",
        "    Convert an image to a tensor to run on the given device.\n",
        "    :param tensor: The data to convert to a tensor.\n",
        "    :param device: The device to use for training being a CUDA GPU if available, otherwise the CPU.\n",
        "    :return: The data ready to be used.\n",
        "    \"\"\"\n",
        "    return tensor.to(device)\n",
        "\n",
        "\n",
        "def dataset_details(title: str, labels):\n",
        "    \"\"\"\n",
        "    Output dataset details to the console.\n",
        "    :param title: The title of the dataset to tell if this is the training or testing dataset.\n",
        "    :param labels: The labels.\n",
        "    :return: The total count of the dataset.\n",
        "    \"\"\"\n",
        "    counts = [0, 0, 0, 0, 0, 0, 0]\n",
        "    for label in labels:\n",
        "        counts[label] += 1\n",
        "    total = sum(counts)\n",
        "    print(f\"{title} Dataset: {total}\\n\"\n",
        "          f\"Angry:    {counts[0]:>5}\\t{counts[0] / total * 100}%\\n\"\n",
        "          f\"Disgust:  {counts[1]:>5}\\t{counts[1] / total * 100}%\\n\"\n",
        "          f\"Fear:     {counts[2]:>5}\\t{counts[2] / total * 100}%\\n\"\n",
        "          f\"Happy:    {counts[3]:>5}\\t{counts[3] / total * 100}%\\n\"\n",
        "          f\"Sad:      {counts[4]:>5}\\t{counts[4] / total * 100}%\\n\"\n",
        "          f\"Surprise: {counts[5]:>5}\\t{counts[5] / total * 100}%\\n\"\n",
        "          f\"Neutral:  {counts[6]:>5}\\t{counts[6] / total * 100}%\")\n",
        "    return total\n",
        "\n",
        "\n",
        "def data_image(dataloader, title: str):\n",
        "    \"\"\"\n",
        "    Generate a sample grid image of the dataset.\n",
        "    :param dataloader: A dataloader.\n",
        "    :param title: The title to give the image.\n",
        "    :return: Nothing.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(os.path.join(os.getcwd(), f\"Data-{title}.png\")):\n",
        "        torchvision.utils.save_image(torchvision.utils.make_grid(iter(dataloader).__next__()[0]), os.path.join(os.getcwd(), f\"Data-{title}.png\"))\n",
        "\n",
        "\n",
        "def test(model, batch: int, dataloader):\n",
        "    \"\"\"\n",
        "    Test a neural network.\n",
        "    :param model: The neural network.\n",
        "    :param batch: The batch size.\n",
        "    :param dataloader: The dataloader to test.\n",
        "    :return: The model's accuracy.\n",
        "    \"\"\"\n",
        "    # Switch to evaluation mode.\n",
        "    model.eval()\n",
        "    # Count how many are correct.\n",
        "    correct = 0\n",
        "    # Loop through all data.\n",
        "    for image, label in dataloader:\n",
        "        # If properly predicted, count it as correct.\n",
        "        correct += (to_tensor(label) == model.predict(to_tensor(image))).sum()\n",
        "    # Calculate the overall accuracy.\n",
        "    return correct / (len(dataloader) * batch) * 100\n",
        "\n",
        "\n",
        "def prepare_data(data):\n",
        "    \"\"\"\n",
        "    Convert the raw pixel data strings for use with PyTorch.\n",
        "    :param data: The data frame loaded from the CSV with emotions and pixel data.\n",
        "    :return: Images and labels ready for PyTorch.\n",
        "    \"\"\"\n",
        "    images = np.zeros(shape=(len(data), 48, 48))\n",
        "    # Break apart the string and resize it as a 48x48 image.\n",
        "    for i, row in enumerate(data.index):\n",
        "        images[i] = np.reshape(np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' '), (48, 48))\n",
        "    # Ensure single channel added for proper inputs and scale all color values between 0 and 1.\n",
        "    return (images.reshape((images.shape[0], 48, 48, 1))).astype('float32') / 255, np.array(list(map(int, data['emotion'])))\n",
        "\n",
        "\n",
        "def save(name: str, mode: str, model, best_model, epoch: int, best_accuracy: float, loss: float):\n",
        "    \"\"\"\n",
        "    Save to a PT file.\n",
        "    :param name: The name of the model architecture.\n",
        "    :param mode: The name of the training mode.\n",
        "    :param model: The model.\n",
        "    :param best_model: The best model state dict.\n",
        "    :param epoch: The current training epoch.\n",
        "    :param best_accuracy: The best accuracy that has been reached.\n",
        "    :param loss: The last training loss.\n",
        "    :return: Nothing.\n",
        "    \"\"\"\n",
        "    torch.save({\n",
        "        'Best': best_model,\n",
        "        'Training': model.state_dict(),\n",
        "        'Optimizer': model.optimizer.state_dict(),\n",
        "        'Epoch': epoch,\n",
        "        'Best Accuracy': best_accuracy,\n",
        "        'Loss': loss\n",
        "    }, f\"{os.getcwd()}/Models/{name}-{mode}.pt\")\n",
        "\n",
        "\n",
        "def write_parameters(name: str, mode: str, best_accuracy: float, train_accuracy: float, inference_time: float, trainable_parameters: int, best_epoch: int):\n",
        "    \"\"\"\n",
        "    Write key parameters to a text file.\n",
        "    :param name: The name of the model architecture.\n",
        "    :param mode: The name of the training mode.\n",
        "    :param best_accuracy: The best accuracy that has been reached.\n",
        "    :param train_accuracy: The training accuracy that has been reached.\n",
        "    :param inference_time: The average inference time.\n",
        "    :param trainable_parameters: The number of trainable parameters in the network.\n",
        "    :param best_epoch: The epoch which the best accuracy was reached on.\n",
        "    \"\"\"\n",
        "    f = open(f\"{os.getcwd()}/Models/{name}-{mode}.txt\", \"w\")\n",
        "    f.write(f\"Testing Accuracy: {best_accuracy}\\n\"\n",
        "            f\"Training Accuracy: {train_accuracy}\\n\"\n",
        "            f\"Average Inference Time: {inference_time} ms\\n\"\n",
        "            f\"Trainable Parameters: {trainable_parameters}\\n\"\n",
        "            f\"Best Epoch: {best_epoch}\")\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def main(epochs: int, batch: int):\n",
        "    \"\"\"\n",
        "    Main program execution.\n",
        "    :param epochs: The number of epochs to train for.\n",
        "    :param batch: The batch size.\n",
        "    :return: Nothing.\n",
        "    \"\"\"\n",
        "    print(f\"Facial Expression Recognition Deep Learning\")\n",
        "    print(f\"Running on GPU with CUDA {torch.version.cuda}.\" if torch.cuda.is_available() else \"Running on CPU.\")\n",
        "    if not os.path.exists(os.path.join(os.getcwd(), \"Data.csv\")):\n",
        "        print(\"Data.csv missing, visit https://github.com/StevenRice99/Facial-Expression-Recognition#setup for instructions.\")\n",
        "        return\n",
        "    # Setup datasets.\n",
        "    print(\"Loading data...\")\n",
        "    # Load CSV.\n",
        "    df = read_csv(os.path.join(os.getcwd(), \"Data.csv\"))\n",
        "    # Split the training and testing data and convert to proper format.\n",
        "    train_images, train_labels = prepare_data(df[df['Usage'] == 'Training'])\n",
        "    test_images, test_labels = prepare_data(df[df['Usage'] != 'Training'])\n",
        "    # Convert into datasets.\n",
        "    training_data = FaceDataset(train_images, train_labels)\n",
        "    testing_data = FaceDataset(test_images, test_labels)\n",
        "    # Display the details and get the length of each dataset.\n",
        "    training_total = dataset_details(\"Training\", train_labels)\n",
        "    testing_total = dataset_details(\"Testing\", test_labels)\n",
        "    # Setup initial data loaders, augmenting the training to start so a sample image can be generated.\n",
        "    training_data.set_transform(1)\n",
        "    training = DataLoader(training_data, batch_size=batch, shuffle=True)\n",
        "    testing = DataLoader(testing_data, batch_size=batch, shuffle=True)\n",
        "    # Generate sample images.\n",
        "    data_image(training, 'Augmented')\n",
        "    data_image(testing, 'Normal')\n",
        "    # Ensure batch size is valid.\n",
        "    if batch < 1:\n",
        "        batch = 1\n",
        "    # Train models.\n",
        "    for name in [\"Simple\", \"ResNet\"]:\n",
        "        # Train each model on every training mode.\n",
        "        for mode in [\"Normal\", \"Augmented\", \"Gradual\"]:\n",
        "            # Check if an existing model for this mode exists.\n",
        "            if os.path.exists(os.path.join(os.getcwd(), \"Models\", f\"{name}-{mode}.pt\")):\n",
        "                try:\n",
        "                    saved = torch.load(os.path.join(os.getcwd(), \"Models\", f\"{name}-{mode}.pt\"))\n",
        "                    epoch = saved['Epoch']\n",
        "                    best_accuracy = saved['Best Accuracy']\n",
        "                    # If already done training this model, skip to the next.\n",
        "                    if epoch >= epochs:\n",
        "                        print(f\"{name} | {mode} | Accuracy = {best_accuracy}%\")\n",
        "                        continue\n",
        "                    model = NeuralNetwork(name)\n",
        "                    model.load_state_dict(saved['Training'])\n",
        "                    model.optimizer.load_state_dict(saved['Optimizer'])\n",
        "                    best_model = saved['Best']\n",
        "                    loss = saved['Loss']\n",
        "                    print(f\"Continuing training for {name} on mode {mode} from epoch {epoch} with batch size {batch} for {epochs} epochs.\")\n",
        "                except:\n",
        "                    print(\"Unable to load training data, exiting.\")\n",
        "                    return\n",
        "            # Create a new model if none already exists.\n",
        "            else:\n",
        "                model = NeuralNetwork(name)\n",
        "                best_model = model.state_dict()\n",
        "                loss = -1\n",
        "                epoch = 1\n",
        "                print(f\"Starting training for {name} on mode {mode} with batch size {batch} for {epochs} epochs.\")\n",
        "            # Ensure folder to save models exists.\n",
        "            if not os.path.exists(os.path.join(os.getcwd(), \"Models\")):\n",
        "                os.mkdir(os.path.join(os.getcwd(), \"Models\"))\n",
        "            # Test the model.\n",
        "            start = time.time_ns()\n",
        "            accuracy = test(model, batch, testing)\n",
        "            end = time.time_ns()\n",
        "            inference_time = ((end - start) / testing_total) / 1e+6\n",
        "            # If new training, write header for new CSV file.\n",
        "            if epoch == 1:\n",
        "                best_accuracy = accuracy\n",
        "                f = open(os.path.join(os.getcwd(), \"Models\", f\"{name}-{mode}.csv\"), \"w\")\n",
        "                f.write(\"Epoch,Loss,Accuracy,Best Accuracy\")\n",
        "                f.close()\n",
        "            train_accuracy = test(model, batch, training)\n",
        "            trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "            write_parameters(name, mode, best_accuracy, train_accuracy, inference_time, trainable_parameters, 0)\n",
        "            save(name, mode, model, best_model, epoch, best_accuracy, loss)\n",
        "            # If not on gradual mode, set the training data as it does not change.\n",
        "            if mode != \"Gradual\":\n",
        "                training_data.set_transform(-1 if mode == \"Normal\" else 1)\n",
        "                training = DataLoader(training_data, batch_size=batch, shuffle=True)\n",
        "            # Loop training.\n",
        "            while True:\n",
        "                # Output final result.\n",
        "                if epoch > epochs:\n",
        "                    print(f\"{name} | {mode} | Accuracy = {best_accuracy}%\")\n",
        "                    break\n",
        "                # Prepare the output message.\n",
        "                loss_message = \"Loss = \" + (f\"{loss:.4}\" if epoch > 1 else \"N/A\")\n",
        "                msg = f\"{name} | {mode} | Epoch {epoch}/{epochs} | {loss_message} | Accuracy = {accuracy:.4}% | Best = {best_accuracy:.4}%\"\n",
        "                # Reset loss every epoch.\n",
        "                loss = 0\n",
        "                # Switch to training mode.\n",
        "                model.train()\n",
        "                # If on gradual mode, increment the data augmentation.\n",
        "                if mode == \"Gradual\":\n",
        "                    training_data.set_transform((epoch - 1) / float(epochs - 1))\n",
        "                    training = DataLoader(training_data, batch_size=batch, shuffle=True)\n",
        "                # Train on the training data.\n",
        "                for image, label in tqdm(training, msg):\n",
        "                    loss += model.optimize(to_tensor(image), to_tensor(label))\n",
        "                loss /= training_total\n",
        "                # Check how well the newest epoch performs.\n",
        "                start = time.time_ns()\n",
        "                accuracy = test(model, batch, testing)\n",
        "                end = time.time_ns()\n",
        "                # Check if this is the new best model.\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_model = model.state_dict()\n",
        "                    best_accuracy = accuracy\n",
        "                    inference_time = ((end - start) / testing_total) / 1e+6\n",
        "                    train_accuracy = test(model, batch, training)\n",
        "                    write_parameters(name, mode, best_accuracy, train_accuracy, inference_time, trainable_parameters, epoch)\n",
        "                # Save data.\n",
        "                f = open(os.path.join(os.getcwd(), \"Models\", f\"{name}-{mode}.csv\"), \"a\")\n",
        "                f.write(f\"\\n{epoch},{loss},{accuracy},{best_accuracy}\")\n",
        "                f.close()\n",
        "                epoch += 1\n",
        "                save(name, mode, model, best_model, epoch, best_accuracy, loss)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=\"Facial Expression Recognition Deep Learning\")\n",
        "        parser.add_argument(\"-e\", \"--epoch\", type=int, help=\"The number of epochs to train for.\", default=100)\n",
        "        parser.add_argument(\"-b\", \"--batch\", type=int, help=\"Training and testing batch size.\", default=64)\n",
        "        a = vars(parser.parse_args())\n",
        "        main(a[\"epoch\"], a[\"batch\"])\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Training Stopped.\")\n",
        "    except torch.cuda.OutOfMemoryError:\n",
        "        print(\"CUDA out of memory. Try running with a smaller batch size.\")\n",
        "    except ValueError as error:\n",
        "        print(error)\n"
      ]
    }
  ]
}